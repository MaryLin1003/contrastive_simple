#!/usr/bin/env python3
"""
é¡¹ç›®å°±ç»ªæ£€æŸ¥è„šæœ¬
"""

import os
import sys
from pathlib import Path

def check_directory_structure():
    """æ£€æŸ¥ç›®å½•ç»“æ„"""
    print("ğŸ“ æ£€æŸ¥ç›®å½•ç»“æ„...")
    
    required_dirs = [
        'configs',
        'configs/ablation',
        'configs/ablation/epochs',
        'configs/ablation/augmentation', 
        'configs/ablation/projection',
        'configs/ablation/batch_size',
        'core',
        'scripts',
        'data',
        'results'
    ]
    
    missing_dirs = []
    for dir_path in required_dirs:
        if not os.path.exists(dir_path):
            missing_dirs.append(dir_path)
    
    if missing_dirs:
        print(f"âŒ ç¼ºå¤±ç›®å½•: {missing_dirs}")
        return False
    else:
        print("âœ… ç›®å½•ç»“æ„å®Œæ•´")
        return True

def check_required_files():
    """æ£€æŸ¥å¿…éœ€æ–‡ä»¶"""
    print("\nğŸ“„ æ£€æŸ¥æ ¸å¿ƒæ–‡ä»¶...")
    
    required_files = [
        'train.py',
        'evaluate.py', 
        'visualize.py',
        'requirements.txt',
        'configs/supervised.yaml',
        'configs/simclr.yaml',
        'configs/moco.yaml',
        'core/__init__.py',
        'core/data.py',
        'core/models.py',
        'core/trainers.py',
        'core/utils.py',
        'scripts/download_data_simple.py'
    ]
    
    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
    
    if missing_files:
        print(f"âŒ ç¼ºå¤±æ–‡ä»¶: {missing_files}")
        return False
    else:
        print("âœ… æ ¸å¿ƒæ–‡ä»¶å®Œæ•´")
        return True

def check_data():
    """æ£€æŸ¥æ•°æ®"""
    print("\nğŸ“Š æ£€æŸ¥æ•°æ®...")
    
    data_dir = Path('./data/cifar-10-batches-py')
    required_data_files = [
        'batches.meta',
        'data_batch_1',
        'data_batch_2',
        'data_batch_3',
        'data_batch_4',
        'data_batch_5',
        'test_batch'
    ]
    
    if not data_dir.exists():
        print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return False
    
    missing_files = []
    for file in required_data_files:
        if not (data_dir / file).exists():
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ ç¼ºå¤±æ•°æ®æ–‡ä»¶: {missing_files}")
        return False
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    total_size = 0
    for file in required_data_files:
        file_path = data_dir / file
        size = file_path.stat().st_size
        total_size += size
    
    print(f"âœ… æ•°æ®æ–‡ä»¶å®Œæ•´")
    print(f"   æ•°æ®ç›®å½•: {data_dir}")
    print(f"   æ€»å¤§å°: {total_size/1024/1024:.1f} MB")
    
    return True

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("\nğŸ”§ æ£€æŸ¥Pythonä¾èµ–...")
    
    required_modules = ['numpy', 'torch', 'torchvision', 'matplotlib', 'sklearn']
    
    missing_modules = []
    for module in required_modules:
        try:
            __import__(module)
        except ImportError:
            missing_modules.append(module)
    
    if missing_modules:
        print(f"âš ï¸  ç¼ºå¤±æ¨¡å—: {missing_modules}")
        print(f"   è¿è¡Œ: pip install -r requirements.txt")
        return False
    else:
        print("âœ… æ ¸å¿ƒä¾èµ–å·²å®‰è£…")
        return True

def quick_test():
    """å¿«é€Ÿæµ‹è¯•"""
    print("\nğŸ§ª å¿«é€ŸåŠŸèƒ½æµ‹è¯•...")
    
    try:
        # æµ‹è¯•å¯¼å…¥æ ¸å¿ƒæ¨¡å—
        print("  æµ‹è¯•å¯¼å…¥æ ¸å¿ƒæ¨¡å—...")
        sys.path.insert(0, '.')
        from core.data import CIFAR10Pair
        from core.models import create_model
        from core.utils import setup_seed, get_device
        print("  âœ… æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•é…ç½®è¯»å–
        print("  æµ‹è¯•é…ç½®è¯»å–...")
        import yaml
        with open('configs/supervised.yaml', 'r') as f:
            config = yaml.safe_load(f)
        print(f"  âœ… é…ç½®è¯»å–æˆåŠŸ: {config['model']['name']}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½ï¼ˆå°æ ·æœ¬ï¼‰
        print("  æµ‹è¯•æ•°æ®åŠ è½½...")
        import torch
        from torch.utils.data import DataLoader
        
        # ä½¿ç”¨ç®€åŒ–çš„æ•°æ®åŠ è½½è¿›è¡Œæµ‹è¯•
        dataset = CIFAR10Pair(root='./data', train=True)
        dataloader = DataLoader(dataset, batch_size=4, shuffle=False)
        
        batch = next(iter(dataloader))
        print(f"  âœ… æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"     æ‰¹æ¬¡å¤§å°: {len(batch)}")
        print(f"     å›¾åƒå½¢çŠ¶: {batch[0][0].shape}")
        
        # æµ‹è¯•æ¨¡å‹åˆ›å»º
        print("  æµ‹è¯•æ¨¡å‹åˆ›å»º...")
        device = get_device(use_cuda=False)  # æµ‹è¯•ç”¨CPU
        model = create_model('supervised')
        model = model.to(device)
        
        print(f"  âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"     æ¨¡å‹ç±»å‹: {type(model).__name__}")
        print(f"     å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("="*60)
    print("é¡¹ç›®å°±ç»ªéªŒè¯æ£€æŸ¥")
    print("="*60)
    
    checks = [
        ("ç›®å½•ç»“æ„", check_directory_structure),
        ("æ ¸å¿ƒæ–‡ä»¶", check_required_files),
        ("æ•°æ®é›†", check_data),
        ("Pythonä¾èµ–", check_dependencies),
        ("å¿«é€ŸåŠŸèƒ½æµ‹è¯•", quick_test)
    ]
    
    all_passed = True
    for check_name, check_func in checks:
        try:
            passed = check_func()
            if not passed:
                all_passed = False
        except Exception as e:
            print(f"âŒ {check_name} æ£€æŸ¥å¼‚å¸¸: {e}")
            all_passed = False
    
    print("\n" + "="*60)
    if all_passed:
        print("ğŸ‰ é¡¹ç›®å®Œå…¨å°±ç»ªï¼å¯ä»¥å¼€å§‹è®­ç»ƒï¼")
        print("\nä¸‹ä¸€æ­¥ï¼š")
        print("1. è¿è¡Œç›‘ç£å­¦ä¹ æµ‹è¯•ï¼špython train.py --model supervised --epochs 5")
        print("2. å¦‚æœæµ‹è¯•æˆåŠŸï¼Œå¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒ")
    else:
        print("âš ï¸  é¡¹ç›®å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œè¯·å…ˆè§£å†³")
    
    print("="*60)

if __name__ == "__main__":
    main()